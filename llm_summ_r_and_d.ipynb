{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00dfefdd-f505-4bf7-b808-124f496fec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q datasets transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04bb4811-6445-4067-bf5a-eaa4db32bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/envs/tbi/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/jp/g5p0_dxs5hn5f7531ws3w1pc0000gp/T/ipykernel_47861/2254352815.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/tbi/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb991fb-2996-411a-a67f-80cd6f2e7a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = get_dataset_config_names(\"ccdv/arxiv-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f882af-bbd4-4e0b-acfe-0f2d2efae8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document', 'section']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac76099-53cf-41f1-a01d-69b99ba0f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_section = load_dataset(\"ccdv/arxiv-summarization\", \"section\", split='train')\n",
    "# ds_doc = load_dataset(\"ccdv/arxiv-summarization\", \"document\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e0e3783-000b-4758-a24c-33ae039ec97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_section, ds_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ed9c6e-1355-4caf-b11b-76604f8ecd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # caching a few samples to use in the future to avoid loading from HF every time\n",
    "# sample_sz = 30\n",
    "# section_samples = ds_section.shuffle(seed=42).select(range(sample_sz))\n",
    "# doc_samples = ds_doc.shuffle(seed=42).select(range(sample_sz))\n",
    "\n",
    "# with open(\"section_samples.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(section_samples[:], f, indent=2)\n",
    "\n",
    "# with open(\"doc_samples.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(doc_samples[:], f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b6349-1d24-4eef-b260-dd48c4cb82ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4caa47d-e65b-4c86-b5b0-975b2ff7d64d",
   "metadata": {},
   "source": [
    "### LLM functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b640fb0-4ac5-4f01-9ea2-7145102d508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "# Load summarization model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb8ecb61-4a69-4a97-955f-001248399060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_summarizer(prompt, tokenizer=tokenizer, model=model,\n",
    "                   max_input_length=1024, min_output_length=20, max_output_length=200):\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        min_length=min_output_length,\n",
    "        max_length=max_output_length,\n",
    "        do_sample=False,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2cea1d48-b052-4b82-baa3-d6f1ff700b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Gabe. I am 29 years old and live in DC. I'm currently on the job market, looking for opportunities in data science or ML engineering. I enjoy working on AI problems that have real-world social impact, particularly in public policy.\n",
      "\n",
      "Summary: Gabe, 29, is looking for opportunities in data science or ML engineering. He enjoys working on AI problems that have real-world social impact.\n",
      "\n",
      "Took 58.88 seconds\n"
     ]
    }
   ],
   "source": [
    "# works pretty well\n",
    "input_text = (\n",
    "    \"My name is Gabe. I am 29 years old and live in DC. \"\n",
    "    \"I'm currently on the job market, looking for opportunities in data science or ML engineering. \"\n",
    "    \"I enjoy working on AI problems that have real-world social impact, particularly in public policy.\"\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "rv = run_summarizer(input_text)\n",
    "print(f\"\\nSummary: {rv}\")\n",
    "print(f\"\\nTook {time.time() - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a9a5b052-cce8-413a-9a75-c015e9a5ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a cached document\n",
    "with open(\"section_samples.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    section_samples = json.load(f)\n",
    "\n",
    "section_article = section_samples['article'][0]\n",
    "section_abstract = section_samples['abstract'][0]\n",
    "\n",
    "user_prompt = \"Summarize the main idea of this paper in one paragraph.\"\n",
    "\n",
    "prompt = f\"{user_prompt}\\n\\nDocument:\\n{section_article}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3007e-f243-4848-bbc0-84ee6908c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rv = run_summarizer(prompt)\n",
    "print(f\"\\nSummary: {rv}\")\n",
    "print(f\"\\nTook {time.time() - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141edb3f-02ea-464a-bc12-e8d6b2a9928a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2394899c-6662-4c50-81be-82cf32deb1b1",
   "metadata": {},
   "source": [
    "### would need diff model for the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4f0b5115-cdf3-4254-8279-426c16759bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you summarize what dropout is and how it is used in deep learning\n",
      "\n",
      "Summary: Can you summarize what dropout is and how it is used in deep learning? Share your thoughts in the comments below.\n",
      "\n",
      "Took 57.50 seconds\n"
     ]
    }
   ],
   "source": [
    "# facebook bart cnn is specifically trained to summarize long docs, this won't work well\n",
    "input_text = \"Can you summarize what dropout is and how it is used in deep learning\"\n",
    "\n",
    "start = time.time()\n",
    "rv = run_summarizer(input_text)\n",
    "print(f\"\\nSummary: {rv}\")\n",
    "print(f\"\\nTook {time.time() - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1743d85-e100-4c71-874b-d2b7ec69a1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43dc3cf-597e-42d4-92b0-7aa5ade4ff54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbi",
   "language": "python",
   "name": "tbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
